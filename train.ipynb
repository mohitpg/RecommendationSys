{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path as osp\n",
    "from pathlib import Path\n",
    "import torch\n",
    "from torch.nn import Linear\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torch_geometric.transforms as T\n",
    "from dataset import MovieLens\n",
    "from torch_geometric.nn import SAGEConv, to_hetero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "path = osp.join(Path().resolve(), 'data')\n",
    "dataset = MovieLens(path, model_name='all-MiniLM-L6-v2')\n",
    "data = dataset[0].to(device)\n",
    "\n",
    "# Add user node features for message passing:\n",
    "data['user'].x = torch.eye(data['user'].num_nodes, device=device)\n",
    "del data['user'].num_nodes\n",
    "\n",
    "# Add a reverse ('movie', 'rev_rates', 'user') relation for message passing:\n",
    "data = T.ToUndirected()(data)\n",
    "del data['movie', 'rev_rates', 'user'].edge_label "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, val_data, test_data = T.RandomLinkSplit(\n",
    "    num_val=0.1,\n",
    "    num_test=0.1,\n",
    "    neg_sampling_ratio=0.0,\n",
    "    edge_types=[('user', 'rates', 'movie')],\n",
    "    rev_edge_types=[('movie', 'rev_rates', 'user')],\n",
    ")(data)\n",
    "\n",
    "# We have an unbalanced dataset with many labels for rating 3 and 4, and very few for 0 and 1. Therefore we use a weighted MSE loss.\n",
    "# Count the frequency of each value in an array of non-negative ints: https://pytorch.org/docs/stable/generated/torch.bincount.html\n",
    "weight = torch.bincount(train_data['user', 'movie'].edge_label)\n",
    "# Take the maximum number of appearences of a rate and normalize all with that number\n",
    "weight = weight.max() / weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model from: https://github.com/vicbeldo98/GNN_mini_example/blob/main/train.py\n",
    "class GNNEncoder(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = SAGEConv((-1, -1), hidden_channels)\n",
    "        self.conv2 = SAGEConv((-1, -1), out_channels)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index).relu()\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x\n",
    "\n",
    "\n",
    "class EdgeDecoder(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels):\n",
    "        super().__init__()\n",
    "        self.lin1 = Linear(2 * hidden_channels, hidden_channels)\n",
    "        self.lin2 = Linear(hidden_channels, 1)\n",
    "\n",
    "    def forward(self, z_dict, edge_label_index):\n",
    "        row, col = edge_label_index\n",
    "        z = torch.cat([z_dict['user'][row], z_dict['movie'][col]], dim=-1)\n",
    "\n",
    "        z = self.lin1(z).relu()\n",
    "        z = self.lin2(z)\n",
    "        return z.view(-1)\n",
    "\n",
    "\n",
    "class Model(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels):\n",
    "        super().__init__()\n",
    "        self.encoder = GNNEncoder(hidden_channels, hidden_channels)\n",
    "        self.encoder = to_hetero(self.encoder, data.metadata(), aggr='sum')\n",
    "        self.decoder = EdgeDecoder(hidden_channels)\n",
    "\n",
    "    def forward(self, x_dict, edge_index_dict, edge_label_index):\n",
    "        z_dict = self.encoder(x_dict, edge_index_dict)\n",
    "        return self.decoder(z_dict, edge_label_index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_mse_loss(pred, target, weight=None):\n",
    "    weight = 1. if weight is None else weight[target].to(pred.dtype)\n",
    "    return (weight * (pred - target.to(pred.dtype)).pow(2)).mean()\n",
    "\n",
    "model = Model(hidden_channels=32).to(device)\n",
    "\n",
    "# Due to lazy initialization, we need to run one model step so the number\n",
    "# of parameters can be inferred:\n",
    "with torch.no_grad():\n",
    "    model.encoder(train_data.x_dict, train_data.edge_index_dict)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    pred = model(train_data.x_dict, train_data.edge_index_dict, train_data['user', 'movie'].edge_label_index)\n",
    "    target = train_data['user', 'movie'].edge_label\n",
    "    loss = weighted_mse_loss(pred, target, weight)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return float(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def test(data):\n",
    "    model.eval()\n",
    "    pred = model(data.x_dict, data.edge_index_dict, data['user', 'movie'].edge_label_index)\n",
    "    pred = pred.clamp(min=0, max=5)\n",
    "    target = data['user', 'movie'].edge_label.float()\n",
    "    rmse = F.mse_loss(pred, target).sqrt()\n",
    "    return float(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 19.3783, Train: 3.3489, Val: 3.3595, Test: 3.3563\n",
      "Epoch: 002, Loss: 17.4074, Train: 3.0623, Val: 3.0742, Test: 3.0706\n",
      "Epoch: 003, Loss: 14.6315, Train: 2.5345, Val: 2.5482, Test: 2.5439\n",
      "Epoch: 004, Loss: 10.4649, Train: 1.6693, Val: 1.6817, Test: 1.6765\n",
      "Epoch: 005, Loss: 6.4561, Train: 1.1545, Val: 1.1255, Test: 1.1263\n",
      "Epoch: 006, Loss: 9.1111, Train: 1.1160, Val: 1.0917, Test: 1.0915\n",
      "Epoch: 007, Loss: 8.4446, Train: 1.1875, Val: 1.1876, Test: 1.1832\n",
      "Epoch: 008, Loss: 6.2441, Train: 1.5928, Val: 1.6037, Test: 1.5986\n",
      "Epoch: 009, Loss: 6.2099, Train: 1.9043, Val: 1.9169, Test: 1.9121\n",
      "Epoch: 010, Loss: 7.0958, Train: 2.0015, Val: 2.0143, Test: 2.0096\n",
      "Epoch: 011, Loss: 7.4739, Train: 1.9281, Val: 1.9409, Test: 1.9360\n",
      "Epoch: 012, Loss: 7.1557, Train: 1.7335, Val: 1.7458, Test: 1.7407\n",
      "Epoch: 013, Loss: 6.4649, Train: 1.4708, Val: 1.4811, Test: 1.4757\n",
      "Epoch: 014, Loss: 5.8725, Train: 1.2261, Val: 1.2312, Test: 1.2259\n",
      "Epoch: 015, Loss: 5.8027, Train: 1.0963, Val: 1.0946, Test: 1.0900\n",
      "Epoch: 016, Loss: 6.1898, Train: 1.0701, Val: 1.0661, Test: 1.0617\n",
      "Epoch: 017, Loss: 6.3480, Train: 1.0972, Val: 1.0973, Test: 1.0922\n",
      "Epoch: 018, Loss: 6.0191, Train: 1.1948, Val: 1.2011, Test: 1.1951\n",
      "Epoch: 019, Loss: 5.6247, Train: 1.3431, Val: 1.3535, Test: 1.3472\n",
      "Epoch: 020, Loss: 5.5137, Train: 1.4795, Val: 1.4919, Test: 1.4856\n",
      "Epoch: 021, Loss: 5.6271, Train: 1.5597, Val: 1.5730, Test: 1.5666\n",
      "Epoch: 022, Loss: 5.7482, Train: 1.5692, Val: 1.5827, Test: 1.5763\n",
      "Epoch: 023, Loss: 5.7343, Train: 1.5118, Val: 1.5251, Test: 1.5185\n",
      "Epoch: 024, Loss: 5.5712, Train: 1.4038, Val: 1.4165, Test: 1.4095\n",
      "Epoch: 025, Loss: 5.3461, Train: 1.2747, Val: 1.2861, Test: 1.2786\n",
      "Epoch: 026, Loss: 5.1903, Train: 1.1637, Val: 1.1731, Test: 1.1652\n",
      "Epoch: 027, Loss: 5.1798, Train: 1.0997, Val: 1.1073, Test: 1.0991\n",
      "Epoch: 028, Loss: 5.2396, Train: 1.0844, Val: 1.0919, Test: 1.0833\n",
      "Epoch: 029, Loss: 5.2069, Train: 1.1110, Val: 1.1202, Test: 1.1112\n",
      "Epoch: 030, Loss: 5.0437, Train: 1.1750, Val: 1.1866, Test: 1.1772\n",
      "Epoch: 031, Loss: 4.8745, Train: 1.2570, Val: 1.2702, Test: 1.2608\n",
      "Epoch: 032, Loss: 4.7992, Train: 1.3246, Val: 1.3387, Test: 1.3292\n",
      "Epoch: 033, Loss: 4.7915, Train: 1.3522, Val: 1.3667, Test: 1.3570\n",
      "Epoch: 034, Loss: 4.7646, Train: 1.3307, Val: 1.3452, Test: 1.3350\n",
      "Epoch: 035, Loss: 4.6682, Train: 1.2680, Val: 1.2823, Test: 1.2713\n",
      "Epoch: 036, Loss: 4.5255, Train: 1.1879, Val: 1.2014, Test: 1.1893\n",
      "Epoch: 037, Loss: 4.4060, Train: 1.1208, Val: 1.1333, Test: 1.1199\n",
      "Epoch: 038, Loss: 4.3525, Train: 1.0873, Val: 1.0990, Test: 1.0845\n",
      "Epoch: 039, Loss: 4.3207, Train: 1.0887, Val: 1.1003, Test: 1.0850\n",
      "Epoch: 040, Loss: 4.2376, Train: 1.1198, Val: 1.1320, Test: 1.1165\n",
      "Epoch: 041, Loss: 4.1155, Train: 1.1698, Val: 1.1827, Test: 1.1673\n",
      "Epoch: 042, Loss: 4.0262, Train: 1.2165, Val: 1.2295, Test: 1.2143\n",
      "Epoch: 043, Loss: 3.9841, Train: 1.2367, Val: 1.2495, Test: 1.2341\n",
      "Epoch: 044, Loss: 3.9413, Train: 1.2221, Val: 1.2344, Test: 1.2182\n",
      "Epoch: 045, Loss: 3.8667, Train: 1.1850, Val: 1.1964, Test: 1.1788\n",
      "Epoch: 046, Loss: 3.7883, Train: 1.1507, Val: 1.1610, Test: 1.1419\n",
      "Epoch: 047, Loss: 3.7539, Train: 1.1387, Val: 1.1483, Test: 1.1281\n",
      "Epoch: 048, Loss: 3.7470, Train: 1.1506, Val: 1.1601, Test: 1.1395\n",
      "Epoch: 049, Loss: 3.7131, Train: 1.1813, Val: 1.1912, Test: 1.1712\n",
      "Epoch: 050, Loss: 3.6642, Train: 1.2206, Val: 1.2309, Test: 1.2117\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, 51):\n",
    "    loss = train()\n",
    "    train_rmse = test(train_data)\n",
    "    val_rmse = test(val_data)\n",
    "    test_rmse = test(test_data)\n",
    "    print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}, Train: {train_rmse:.4f}, 'f'Val: {val_rmse:.4f}, Test: {test_rmse:.4f}')\n",
    "    if epoch%10==0:\n",
    "        torch.save(model.state_dict(),f\"models/model{epoch//10}.pt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
